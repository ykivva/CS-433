{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = os.path.join(os.getcwd(), '../data/train.csv')\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our CRAZY machine learning thing :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_model import NNModel\n",
    "from preprocessing import *\n",
    "from nn_model import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing()\n",
    "y[y==-1] = 0\n",
    "y = y.astype(np.int)\n",
    "preprocessing.replace_outliers_by_nan(tX)\n",
    "\n",
    "#Delete rows from tX and y, which has more than 8 nan values in tX and 0 label in y\n",
    "num_nan_in_row = np.isnan(tX).sum(axis=1)\n",
    "mask = (y==0) & (num_nan_in_row>8)\n",
    "y = y[~mask]\n",
    "tX = tX[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparamters_tunning(x_train, y_train,\n",
    "                           x_val, y_val,\n",
    "                           use_transformations, handling_outliers, degrees,\n",
    "                           lrs, lambdas, epochs, batch_size):\n",
    "    best = {\n",
    "        \"models_feat\": {},\n",
    "        \"model\": None,\n",
    "        \"transformation\": None,\n",
    "        \"handling_outlier\": None,\n",
    "        \"degree\": None,\n",
    "        \"accuracy\": 0,\n",
    "        \"lr\": None,\n",
    "        \"lambda\": None,\n",
    "    }\n",
    "    models = {}\n",
    "    model = None\n",
    "    units = 1\n",
    "    activation = 'sigmoid'\n",
    "    for use_transformation in use_transformations:\n",
    "        for handling_outlier in handling_outliers:\n",
    "            for lr in lrs:\n",
    "                for lambda_ in lambdas:\n",
    "                    for degree in degrees:\n",
    "                        preprocessing = Preprocessing(\n",
    "                            use_transformations=use_transformation,\n",
    "                            handling_outliers=handling_outlier,\n",
    "                        )\n",
    "                        train_data, models = preprocessing.preprocess(\n",
    "                            x_train,\n",
    "                            lr=lr,\n",
    "                            lambda_=lambda_,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            degrees=degree\n",
    "                        )\n",
    "                        \n",
    "                        for lr in lrs:\n",
    "                            for lamda_ in lambdas:\n",
    "                                model = NNModel(train_data.shape[1])\n",
    "                                model.add_layer(1, activation='sigmoid')\n",
    "                                model.train(train_data, y_train, lr=lr,\n",
    "                                            lambda_=lambda_,\n",
    "                                            batch_size=batch_size, epochs=100,\n",
    "                                            verbose=1)\n",
    "                                preprocessing = Preprocessing(\n",
    "                                    use_transformations=use_transformation,\n",
    "                                    handling_outliers = handling_outlier,\n",
    "                                )\n",
    "                                val_data, _ = preprocessing.preprocess(\n",
    "                                    x_val,\n",
    "                                    train=False,\n",
    "                                    models=models,\n",
    "                                    degrees=degree\n",
    "                                )\n",
    "                                \n",
    "                                y_pred = model.predict(val_data)\n",
    "                                y_pred = y_pred > 0.5\n",
    "                                y_pred = y_pred.squeeze()\n",
    "                                accuracy = (y_pred==y_val).mean()\n",
    "                                if accuracy > best[\"accuracy\"]:\n",
    "                                    print(\"Best is updated with accuracy:\", accuracy)\n",
    "                                    best[\"models_feat\"] = models\n",
    "                                    best[\"model\"] = model\n",
    "                                    best[\"transformation\"] = use_transformation\n",
    "                                    best[\"handling_outlier\"] = handling_outlier\n",
    "                                    best[\"degree\"] = degree\n",
    "                                    best[\"accuracy\"] = accuracy\n",
    "                                    best[\"lambda\"] = lambda_\n",
    "                                    best[\"lr\"] = lr\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = tX.shape[0]\n",
    "val_size = 10000\n",
    "train_samples = np.random.choice(num_examples, replace=False, size=val_size)\n",
    "mask_val = np.isin(np.arange(tX.shape[0]), train_samples)\n",
    "x_val, y_val = tX[mask_val], y[mask_val]\n",
    "x_train, y_train = tX[~mask_val], y[~mask_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_transformations = [False]\n",
    "handling_outliers = ['predict', 'fill_mean', 'remove']\n",
    "lrs = [0.01, 0.1]\n",
    "lambdas = [0.3, 1, 10]\n",
    "degrees = [np.arange(2, 5)]\n",
    "epochs = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesing started!\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 7.846122817948441\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 10.83490184831185\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 9.113505384771914\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 11.522920802590024\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 13.116643339484433\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 7.6213049455049235\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 469.47625688557133\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 9.846582418795833\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 10.853308414534204\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 13.88827262796391\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 10.391361191583663\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 8.183486817802853\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 11.00170775943251\n",
      "Training ended\n",
      "\n",
      "Preprocessing ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 0.23277611458186462\n",
      "Training ended\n",
      "\n",
      "Preprocesing started!\n",
      "\n",
      "Preprocessing ended\n",
      "\n",
      "Best is updated with accuracy: 0.5086\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 0.27522411092163895\n",
      "Training ended\n",
      "\n",
      "Preprocesing started!\n",
      "\n",
      "Preprocessing ended\n",
      "\n",
      "Training started\n",
      ">Epoch #100:\t[####################]; Loss: 0.2146725559533454\n",
      "Training ended\n",
      "\n",
      "Preprocesing started!\n",
      "\n",
      "Preprocessing ended\n",
      "\n",
      "Best is updated with accuracy: 0.5331\n",
      "Training started\n",
      ">Epoch #75:\t[###############     ]; Loss: 0.17335988874009563"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c67c548376b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0mlambdas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                              )\n",
      "\u001b[0;32m<ipython-input-12-bf1f1ea186a0>\u001b[0m in \u001b[0;36mhyperparamters_tunning\u001b[0;34m(x_train, y_train, x_val, y_val, use_transformations, handling_outliers, degrees, lrs, lambdas, epochs, batch_size)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                             \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                                             verbose=1)\n\u001b[0m\u001b[1;32m     45\u001b[0m                                 preprocessing = Preprocessing(\n\u001b[1;32m     46\u001b[0m                                     \u001b[0muse_transformations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_transformation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yaroslav/education/epfl/CS-433/projects/project1/scripts/nn_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, lr, lambda_, batch_size, epochs, verbose, loss_fun, momentum)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_shuffled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mget_loss_grad\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNNModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'_get_{loss_fun}_grad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yaroslav/education/epfl/CS-433/projects/project1/scripts/nn_model.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mact_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNNModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'a{num_layer}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'h{num_layer}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'a{num_layer}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'h{num_layer}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yaroslav/education/epfl/CS-433/projects/project1/scripts/nn_model.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(output, lower_bound, upper_bound)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0moutput_bounded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mupper_bound\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0moutput_bounded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlower_bound\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutput_bounded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best = hyperparamters_tunning(x_train, y_train,\n",
    "                              x_val, y_val,\n",
    "                              use_transformations=use_transformations,\n",
    "                              handling_outliers=handling_outliers,\n",
    "                              degrees=degrees,\n",
    "                              lrs=lrs,\n",
    "                              lambdas=lambdas,\n",
    "                              epochs=epochs,\n",
    "                              batch_size=batch_size\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best[\"model\"]\n",
    "best[\"models_feat\"] = models\n",
    "use_transformation = best[\"transformation\"]\n",
    "handling_outlier = best[\"handling_outlier\"]\n",
    "degree = best[\"degree\"]\n",
    "accuracy = best[\"accuracy\"]\n",
    "lambda_ = best[\"lambda\"]\n",
    "lr = best[\"lr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "data = pd.read_csv('../data/train.csv')\n",
    "data = data.drop(columns=['Id'])\n",
    "mask = (data.loc[:, 'Prediction'] == 's').values\n",
    "data.loc[mask, ('Prediction')] = 1\n",
    "data.loc[~mask, ('Prediction')] = 0\n",
    "data = data.astype({'Prediction': np.int})\n",
    "\n",
    "data[data==-999] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fd83b241250>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842ebf7d0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842e74d50>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842e36310>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd842ded890>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842da2e10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842d64450>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842d1a910>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd842d1a950>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842d4ffd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842cc7a10>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842c7df90>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x7fd842c40550>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842bf5ad0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842ba0b90>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fd842b6d610>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "data.iloc[:, :15].hist()\n",
    "data.iloc[:, 15:].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>DER_sum_pt</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>211886.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>150087.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>72543.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>121.858528</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>2.403735</td>\n",
       "      <td>371.783360</td>\n",
       "      <td>-0.821688</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>158.432217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>84.822105</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>-0.012393</td>\n",
       "      <td>57.679474</td>\n",
       "      <td>-0.011845</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>57.298157</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>1.742226</td>\n",
       "      <td>397.699325</td>\n",
       "      <td>3.584362</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>115.706115</td>\n",
       "      <td>...</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>60.662276</td>\n",
       "      <td>1.784546</td>\n",
       "      <td>1.813385</td>\n",
       "      <td>31.985782</td>\n",
       "      <td>2.031743</td>\n",
       "      <td>1.816950</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.044000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.602000</td>\n",
       "      <td>-18.066000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.104000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>91.885250</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>111.977000</td>\n",
       "      <td>-2.629000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>77.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.422500</td>\n",
       "      <td>-1.342000</td>\n",
       "      <td>-1.584000</td>\n",
       "      <td>37.312000</td>\n",
       "      <td>-1.612000</td>\n",
       "      <td>-1.576500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>112.406000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>2.107000</td>\n",
       "      <td>225.885000</td>\n",
       "      <td>-0.244000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>120.664500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.561000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>47.902000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>135.482000</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>478.226000</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>200.478250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>103.342000</td>\n",
       "      <td>1.336000</td>\n",
       "      <td>1.562000</td>\n",
       "      <td>66.637000</td>\n",
       "      <td>1.589500</td>\n",
       "      <td>1.576000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>1852.462000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DER_mass_MMC  DER_mass_transverse_met_lep   DER_mass_vis  \\\n",
       "count  211886.000000                250000.000000  250000.000000   \n",
       "mean      121.858528                    49.239819      81.181982   \n",
       "std        57.298157                    35.344886      40.828691   \n",
       "min         9.044000                     0.000000       6.329000   \n",
       "25%        91.885250                    19.241000      59.388750   \n",
       "50%       112.406000                    46.524000      73.752000   \n",
       "75%       135.482000                    73.598000      92.259000   \n",
       "max      1192.026000                   690.075000    1349.351000   \n",
       "\n",
       "            DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "count  250000.000000          72543.000000      72543.000000   \n",
       "mean       57.895962              2.403735        371.783360   \n",
       "std        63.655682              1.742226        397.699325   \n",
       "min         0.000000              0.000000         13.602000   \n",
       "25%        14.068750              0.882500        111.977000   \n",
       "50%        38.467500              2.107000        225.885000   \n",
       "75%        79.169000              3.690000        478.226000   \n",
       "max      2834.999000              8.503000       4974.979000   \n",
       "\n",
       "       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot     DER_sum_pt  \\\n",
       "count         72543.000000       250000.000000  250000.000000  250000.000000   \n",
       "mean             -0.821688            2.373100      18.917332     158.432217   \n",
       "std               3.584362            0.782911      22.273494     115.706115   \n",
       "min             -18.066000            0.208000       0.000000      46.104000   \n",
       "25%              -2.629000            1.810000       2.841000      77.550000   \n",
       "50%              -0.244000            2.491500      12.315500     120.664500   \n",
       "75%               0.958000            2.961000      27.591000     200.478250   \n",
       "max              16.690000            5.684000    2834.999000    1852.462000   \n",
       "\n",
       "       ...    PRI_met_phi  PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  \\\n",
       "count  ...  250000.000000  250000.000000  250000.000000       150087.000000   \n",
       "mean   ...      -0.010119     209.797178       0.979176           84.822105   \n",
       "std    ...       1.812223     126.499506       0.977426           60.662276   \n",
       "min    ...      -3.142000      13.678000       0.000000           30.000000   \n",
       "25%    ...      -1.575000     123.017500       0.000000           44.422500   \n",
       "50%    ...      -0.024000     179.739000       1.000000           65.561000   \n",
       "75%    ...       1.561000     263.379250       2.000000          103.342000   \n",
       "max    ...       3.142000    2003.976000       3.000000         1120.573000   \n",
       "\n",
       "       PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n",
       "count        150087.000000        150087.000000           72543.000000   \n",
       "mean             -0.003275            -0.012393              57.679474   \n",
       "std               1.784546             1.813385              31.985782   \n",
       "min              -4.499000            -3.142000              30.000000   \n",
       "25%              -1.342000            -1.584000              37.312000   \n",
       "50%               0.000000            -0.033000              47.902000   \n",
       "75%               1.336000             1.562000              66.637000   \n",
       "max               4.499000             3.141000             721.456000   \n",
       "\n",
       "       PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "count            72543.000000            72543.000000   250000.000000  \n",
       "mean                -0.011845               -0.001582       73.064591  \n",
       "std                  2.031743                1.816950       98.015662  \n",
       "min                 -4.500000               -3.142000        0.000000  \n",
       "25%                 -1.612000               -1.576500        0.000000  \n",
       "50%                 -0.010000               -0.002000       40.512500  \n",
       "75%                  1.589500                1.576000      109.933750  \n",
       "max                  4.500000                3.142000     1633.433000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "mask = \n",
    "data.iloc[data., :15].hist()\n",
    "data.iloc[:, 15:].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with given hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = os.path.join(os.getcwd(), '../data/train.csv')\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "\n",
    "preprocessing = Preprocessing()\n",
    "y[y==-1] = 0\n",
    "y = y.astype(np.int)\n",
    "preprocessing.replace_outliers_by_nan(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete rows from tX and y, which has more than 8 nan values in tX and 0 label in y\n",
    "num_nan_in_row = np.isnan(tX).sum(axis=1)\n",
    "mask = (y==0) & (num_nan_in_row>8)\n",
    "y = y[~mask]\n",
    "tX = tX[~mask]\n",
    "\n",
    "#Create train and validate sets\n",
    "num_examples = tX.shape[0]\n",
    "val_size = 10000\n",
    "train_samples = np.random.choice(num_examples, replace=False, size=val_size)\n",
    "mask_val = np.isin(np.arange(tX.shape[0]), train_samples)\n",
    "x_val, y_val = tX[mask_val], y[mask_val]\n",
    "x_train, y_train = tX[~mask_val], y[~mask_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_transformation = False\n",
    "handling_outlier = 'predict'\n",
    "lr = 0.1\n",
    "lambda_ = 100\n",
    "degree = np.arange(2, 5)\n",
    "epochs_preprocess = 10\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "units = 1\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesing started!\n",
      "\n",
      "[[4.35157936e-04 8.59632332e-01 1.76750908e+00 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [1.16103275e-09 2.20675604e+04 2.55959438e+00 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [7.17331933e-06 1.01090913e+01 2.55959438e+00 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [2.73713058e-48 2.70517611e+00 1.98021339e-03 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.51452501e-03 1.78126601e-34 1.66079947e+00 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [5.65277906e-07 6.97495144e-22 6.98481874e-15 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n",
      "Training started\n",
      ">Epoch #50:\t[####################]; Loss: nan\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #50:\t[####################]; Loss: nan\n",
      "Training ended\n",
      "\n",
      "Training started\n",
      ">Epoch #33:\t[#############       ]; Loss: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2ac23d1ce6e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdegrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yaroslav/education/epfl/CS-433/projects/project1/scripts/preprocessing.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, data_, lr, lambda_, batch_size, epochs, degrees, train, models, momentum)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandling_outliers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_Nans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Value of handling_NaNs is not acceptable'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yaroslav/education/epfl/CS-433/projects/project1/scripts/preprocessing.py\u001b[0m in \u001b[0;36mpredict_Nans\u001b[0;34m(self, data_, lr, lambda_, batch_size, epochs, train, models, momentum)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/yaroslav/education/epfl/CS-433/projects/project1/scripts/nn_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x, y, lr, lambda_, batch_size, epochs, verbose, loss_fun, momentum)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mdecay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mpermut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mx_shuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpermut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0my_shuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpermut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "preprocessing = Preprocessing(\n",
    "    use_transformations=use_transformation,\n",
    "    handling_outliers=handling_outlier,\n",
    ")\n",
    "train_data, models = preprocessing.preprocess(\n",
    "    x_train,\n",
    "    lr=lr,\n",
    "    lambda_=lambda_,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    degrees=degree\n",
    ")\n",
    "\n",
    "model = NNModel(train_data.shape[1])\n",
    "model.add_layer(units=units, activation=activation)\n",
    "model.train(train_data, y_train, lr=lr,\n",
    "            lambda_=lambda_,\n",
    "            batch_size=batch_size, epochs=epochs,\n",
    "            verbose=1)\n",
    "\n",
    "preprocessing = Preprocessing(\n",
    "    use_transformations=use_transformation,\n",
    "    handling_outliers = handling_outlier,\n",
    ")\n",
    "val_data, _ = preprocessing.preprocess(\n",
    "    x_val,\n",
    "    train=False,\n",
    "    models=models,\n",
    "    degrees=degree\n",
    ")\n",
    "\n",
    "y_pred = model.predict(val_data)\n",
    "y_pred = y_pred > 0.5\n",
    "y_pred = y_pred.squeeze()\n",
    "accuracy = (y_pred==y_val).mean()\n",
    "print(\"Validation arruracy is\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[res] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred==y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = DATA_TRAIN_PATH = os.path.join(os.getcwd(), '../data/test.csv')\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocesing started!\n",
      "\n",
      "Preprocessing ended\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessing = Preprocessing(\n",
    "    use_transformations=use_transformation,\n",
    "    handling_outliers = handling_outlier,\n",
    ")\n",
    "test_data, _ = preprocessing.preprocess(\n",
    "    tX_test,\n",
    "    train=False,\n",
    "    models=models,\n",
    "    degrees=degree\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'prediction.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = model.predict(test_data)\n",
    "res = y_pred>0.5\n",
    "res = res.squeeze()\n",
    "pred = -np.ones(res.shape)\n",
    "pred[res] = 1\n",
    "create_csv_submission(ids_test, pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
